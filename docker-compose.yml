services:
  redis:
    image: redis:7-alpine
    container_name: redis_store
    ports:
      - "6379:6379"
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
    volumes:
      - ./redis_data:/data
    restart: always

  # atrocity-game-app:
  #   image: node:20-alpine
  #   container_name: atrocity_game
  #   working_dir: /app
  #   volumes:
  #     - .:/app
  #     - /app/node_modules
  #   environment:
  #     - REDIS_HOST=redis
  #     - REDIS_PORT=6379
  #     - AI_PROVIDER=ollama
  #     - NODE_ENV=production
  #   ports:
  #     - "3000:3000"
  #     - "3001:3001"
  #   depends_on:
  #     - redis
  #   command: sh -c "npm install && npm run dev"

  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama_engine
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ./ollama_data:/root/.ollama
  #   restart: always

  # ollama-init:
  #   image: curlimages/curl
  #   container_name: ollama_puller
  #   depends_on:
  #     - ollama
  #   command: >
  #     /bin/sh -c "
  #     echo 'Waiting for Ollama service...';
  #     until curl -s http://ollama:11434/ > /dev/null; do
  #       echo 'Retrying connection to Ollama...';
  #       sleep 5;
  #     done;
  #     echo 'Ollama is up. Checking for phi3:mini...';
  #     if curl -s http://ollama:11434/api/tags | grep -q 'phi3:mini'; then
  #        echo 'Model phi3:mini already exists.';
  #     else
  #        echo 'Model not found. Pulling phi3:mini...';
  #        curl -X POST http://ollama:11434/api/pull -d '{\"name\": \"phi3:mini\"}';
  #        echo 'Model pull request sent.';
  #     fi
  #     "
